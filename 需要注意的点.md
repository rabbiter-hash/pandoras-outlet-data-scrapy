# 注意

## 一、数据的结构化存储

### 1. 选择器的数据结构化

```python
		# 使用安全的数据提取方法
        selectors = {
            'product_name': './/h1[@class="heading-title"]/text()',
            'product_model': './/span[@class="p-model"]/text()',
            'product_original_price': './/li[@class="price-old"]/text()',
            'product_discount_price': './/li[@class="price-new"]/text()',
            'product_main_image': './/img[@id="image"]/@src'
        }

        for field, selector in selectors.items():
            value = response.xpath(selector).extract_first()
            if (field in ['product_original_price', 'product_discount_price']) and value:
                # 两个条件同时满足
                # print(field, value, sep="*" * 50)
                value = re.sub(r"\$", "", value)
                # print("第三次：" + value + "*"*50)
            item[field] = value or ''
```

这里将 `item.py` 中定义的字段与选择器进行了字典结构化。

## 二、xpath语法

### A. 翻页规则

翻页规则通过取值进行指定。

```python
		# 获取下一页链接
        next_page = response.xpath('//div[contains(@class, "pagination")]//a[text()=">"]/@href').extract_first()
        # 注意提取链接的表达式
        if next_page:
            self.logger.info(f"找到下一页: {next_page}")
            yield scrapy.Request(
                url=response.urljoin(next_page),
                callback=self.parse
            )
        else:
            self.logger.info("没有下一页了，爬取结束")
```

这里的翻页没有明显的class可用，使用的是 `a[text()=">"]`，因为在网页上 `>` 的值就是下一页链接的值。

### B. 选择器指定选取

在这个项目中，细节图的第一张是主图，已经有字段处理主图了。所以在处理细节图的时候，需要把第一张图的链接给去掉。也就是类似如下：

```html
<a>
  <img src="1.jpg" />
  <img src="2.jpg" />  <!-- 选中这个 -->
  <img src="3.jpg" />  <!-- 和这个 -->
</a>
```

第一张图的值，跟处理字段中 `item['main_image_url']` 的值是一模一样的，所以这里选取的时候，需要丢掉第一张，xpath语法如下：

```python
        try:
            # item['product_detail_images'] = response.xpath('.//div[@class="swiper-wrapper"]/a/@href').extract() or []
            item['product_detail_images'] = response.xpath('.//div[@class="swiper-wrapper"]/a[position() > 1]/@href').extract() or []
        except Exception as e:
            self.logger.error(f"Error extracting detail images: {str(e)}")
            item['product_detail_images'] = []
```

也就是 `a[position() > 1]` 。

## 三、可优化的地方

因为爬取网页的时候是手动更改 `start_urls`、`category_ifno`的一级目录和二级目录信息，是否可以结构化到字典？